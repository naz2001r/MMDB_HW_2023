{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e329535",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sseclient import SSEClient as EventSource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b01b285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://stream.wikimedia.org/v2/stream/recentchange'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d65f6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 'Gzen92Bot' is a bot\n",
      "User 'Aidas' isn't a bot\n",
      "User 'Lutheraner' isn't a bot\n",
      "User 'Luca.favorido' isn't a bot\n",
      "User 'Manuele9866' isn't a bot\n",
      "User 'AgainErick' isn't a bot\n",
      "User 'Marchjuly' isn't a bot\n",
      "User '円周率３パーセント' isn't a bot\n",
      "User '213.55.226.65' isn't a bot\n",
      "User 'Higa4' isn't a bot\n",
      "User '213.55.226.65' isn't a bot\n",
      "User '2001:B011:8007:10C4:5131:1454:AE5D:B376' isn't a bot\n",
      "User 'Bot-Jagwar' is a bot\n",
      "User '190.21.247.59' isn't a bot\n",
      "User 'AgainErick' isn't a bot\n",
      "User '95.237.7.141' isn't a bot\n",
      "User 'GeographBot' is a bot\n",
      "User 'KrBot' is a bot\n",
      "User 'Fuzheado' isn't a bot\n",
      "User 'Escargot mécanique' is a bot\n",
      "User 'AgainErick' isn't a bot\n",
      "Total Bot Edits: 5\n",
      "Total Non-Bot Edits: 16\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "maxEvents = 100  # print n events and stop\n",
    "\n",
    "bot = 0\n",
    "non_bot = 0\n",
    "\n",
    "for event in EventSource(url):\n",
    "    if event.event == 'message':\n",
    "        try:\n",
    "            change = json.loads(event.data)\n",
    "        except ValueError:\n",
    "            continue\n",
    "      \n",
    "        if counter % 5 == 0:\n",
    "\n",
    "            if change['bot'] == False:\n",
    "                non_bot += 1\n",
    "                print(\"User '{user}' isn't a bot\".format(**change))\n",
    "            else:\n",
    "                bot += 1\n",
    "                print(\"User '{user}' is a bot\".format(**change))\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        if counter > maxEvents:\n",
    "            break\n",
    "\n",
    "\n",
    "print(f\"Total Bot Edits: {bot}\")\n",
    "print(f\"Total Non-Bot Edits: {non_bot}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210de402",
   "metadata": {},
   "source": [
    "## Train the Bloom filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a838a63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Bloom Filter Parameters: Estimated Capacity=1000, Desired Error Rate=0.001\n",
      "Actual False Positive Rate for Bloom filter with best parameters: 6.93%\n"
     ]
    }
   ],
   "source": [
    "from pybloom_live import BloomFilter\n",
    "\n",
    "maxEvents = 100  # print n events and stop\n",
    "\n",
    "best_false_positive_rate_actual = 0.1\n",
    "best_capacity = 0\n",
    "best_false_positive_rate = 0\n",
    "\n",
    "# Iterate through different Bloom Filter parameters\n",
    "for candidate_capacity in [100, 1000, 10000]:\n",
    "    for candidate_false_positive_rate in [0.001, 0.01, 0.1]:\n",
    "        # Initialize the Bloom Filter with candidate parameters\n",
    "        bloom_filter = BloomFilter(candidate_capacity, candidate_false_positive_rate)\n",
    "\n",
    "        # Initialize variables to track users who are bots and non-bots\n",
    "        changes = []\n",
    "        counter = 0\n",
    "       \n",
    "        for event in EventSource(url):\n",
    "            if event.event == 'message':\n",
    "                try:\n",
    "                    change = json.loads(event.data)\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                if counter % 5 == 0:\n",
    "                    # Train the Bloom Filter with bot users\n",
    "                    if change['bot'] == True:\n",
    "                        bloom_filter.add(change['user'])\n",
    "                changes.append(change)  # Accumulate changes for future analysis of users\n",
    "                counter += 1\n",
    "\n",
    "                if counter > maxEvents:\n",
    "                    break\n",
    "\n",
    "        # Calculate the actual False Positive Rate \n",
    "        false_positive_rate_actual = len([user for user in changes if bloom_filter.__contains__(user['user'])]) / len(changes)\n",
    "        if false_positive_rate_actual < best_false_positive_rate_actual:\n",
    "            best_false_positive_rate_actual = false_positive_rate_actual\n",
    "            best_capacity = candidate_capacity\n",
    "            best_false_positive_rate = candidate_false_positive_rate\n",
    "        changes = []\n",
    "        counter = 0\n",
    "        \n",
    "#Print the best parameters and their actual False Positive Rate\n",
    "print(f\"Best Bloom Filter Parameters: Estimated Capacity={best_capacity}, Desired Error Rate={best_false_positive_rate}\")\n",
    "print(f\"Actual False Positive Rate for Bloom filter with best parameters: {best_false_positive_rate_actual:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa9a33e",
   "metadata": {},
   "source": [
    "## Spark Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d745573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.streaming import StreamingContext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f1b89f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a SparkContext\n",
    "sc = SparkContext('local[*]')\n",
    "\n",
    "# Create a StreamingContext with a batch interval of 10 second\n",
    "ssc = StreamingContext(sc, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "df4e072f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Bloom Filter Parameters: Estimated Capacity=1000, Desired Error Rate=0.1\n",
      "Actual False Positive Rate for Bloom filter with best parameters: 1.96%\n",
      "Best Bloom Filter Parameters: Estimated Capacity=100, Desired Error Rate=0.001\n",
      "Actual False Positive Rate for Bloom filter with best parameters: 5.88%\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o16455.awaitTermination.\n: org.apache.spark.SparkException: An exception was raised by Python:\nTraceback (most recent call last):\n  File \"C:\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\util.py\", line 71, in call\n    r = self.func(t, *rdds)\n  File \"C:\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\dstream.py\", line 236, in func\n    return old_func(rdd)  # type: ignore[call-arg, arg-type]\n  File \"C:\\Users\\Уляна\\AppData\\Local\\Temp\\ipykernel_23136\\3241030011.py\", line 18, in process_batch\n    for event in EventSource(url):\n  File \"C:\\anaconda3\\lib\\site-packages\\sseclient.py\", line 48, in __init__\n    self._connect()\n  File \"C:\\anaconda3\\lib\\site-packages\\sseclient.py\", line 63, in _connect\n    self.resp.raise_for_status()\n  File \"C:\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://stream.wikimedia.org/v2/stream/recentchange\n\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\r\n\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 57\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# Start the Spark Streaming context\u001b[39;00m\n\u001b[0;32m     56\u001b[0m ssc\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m---> 57\u001b[0m \u001b[43mssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\context.py:239\u001b[0m, in \u001b[0;36mStreamingContext.awaitTermination\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;124;03mWait for the execution to stop.\u001b[39;00m\n\u001b[0;32m    232\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;124;03m    time to wait in seconds\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 239\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jssc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mawaitTermination\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jssc\u001b[38;5;241m.\u001b[39mawaitTerminationOrTimeout(\u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m))\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\anaconda3\\lib\\site-packages\\py4j\\protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[1;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[0;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[0;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[0;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o16455.awaitTermination.\n: org.apache.spark.SparkException: An exception was raised by Python:\nTraceback (most recent call last):\n  File \"C:\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\util.py\", line 71, in call\n    r = self.func(t, *rdds)\n  File \"C:\\anaconda3\\lib\\site-packages\\pyspark\\streaming\\dstream.py\", line 236, in func\n    return old_func(rdd)  # type: ignore[call-arg, arg-type]\n  File \"C:\\Users\\Уляна\\AppData\\Local\\Temp\\ipykernel_23136\\3241030011.py\", line 18, in process_batch\n    for event in EventSource(url):\n  File \"C:\\anaconda3\\lib\\site-packages\\sseclient.py\", line 48, in __init__\n    self._connect()\n  File \"C:\\anaconda3\\lib\\site-packages\\sseclient.py\", line 63, in _connect\n    self.resp.raise_for_status()\n  File \"C:\\anaconda3\\lib\\site-packages\\requests\\models.py\", line 1021, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nrequests.exceptions.HTTPError: 429 Client Error: Too Many Requests for url: https://stream.wikimedia.org/v2/stream/recentchange\n\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:95)\r\n\tat org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:78)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.api.python.PythonDStream$.$anonfun$callForeachRDD$1$adapted(PythonDStream.scala:179)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$2(ForEachDStream.scala:51)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:417)\r\n\tat org.apache.spark.streaming.dstream.ForEachDStream.$anonfun$generateJob$1(ForEachDStream.scala:51)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.Try$.apply(Try.scala:213)\r\n\tat org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)\r\n\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.$anonfun$run$1(JobScheduler.scala:256)\r\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\r\n\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\r\n\tat org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:256)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)\r\n\tat java.base/java.lang.Thread.run(Thread.java:829)\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to process each batch of events\n",
    "def process_batch(rdd):\n",
    "    # Initialize variables to track the best parameters\n",
    "    best_capacity = 0\n",
    "    best_false_positive_rate = 0\n",
    "    best_false_positive_rate_actual = 0.1  \n",
    "    maxEvents = 50\n",
    "    # Iterate through different Bloom Filter parameters\n",
    "    for candidate_capacity in [100, 1000, 10000]:\n",
    "        for candidate_false_positive_rate in [0.001, 0.01, 0.1]:\n",
    "            # Initialize the Bloom Filter with candidate parameters\n",
    "            bloom_filter = BloomFilter(candidate_capacity, candidate_false_positive_rate)\n",
    "\n",
    "            # Initialize variables to track users who are bots and non-bots\n",
    "            changes = []\n",
    "            counter = 0\n",
    "\n",
    "            for event in EventSource(url):\n",
    "                if event.event == 'message':\n",
    "                    try:\n",
    "                        change = json.loads(event.data)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "                    if counter % 5 == 0:\n",
    "                        # Train the Bloom Filter with bot users\n",
    "                        if change['bot'] == True:\n",
    "                            bloom_filter.add(change['user'])\n",
    "                    changes.append(change)  # Accumulate changes for future analysis of users\n",
    "                    counter += 1\n",
    "\n",
    "                    if counter > maxEvents:\n",
    "                        break\n",
    "\n",
    "            # Calculate the actual False Positive Rate \n",
    "            false_positive_rate_actual = len([user for user in changes if bloom_filter.__contains__(user['user'])]) / len(changes)\n",
    "            if false_positive_rate_actual < best_false_positive_rate_actual:\n",
    "                best_false_positive_rate_actual = false_positive_rate_actual\n",
    "                best_capacity = candidate_capacity\n",
    "                best_false_positive_rate = candidate_false_positive_rate\n",
    "            changes = []\n",
    "            counter = 0\n",
    "            \n",
    "    #Print the best parameters and their actual False Positive Rate\n",
    "    print(f\"Best Bloom Filter Parameters: Estimated Capacity={best_capacity}, Desired Error Rate={best_false_positive_rate}\")\n",
    "    print(f\"Actual False Positive Rate for Bloom filter with best parameters: {best_false_positive_rate_actual:.2%}\")\n",
    "\n",
    "\n",
    "# Create a DStream from the EventSource\n",
    "dstream = ssc.socketTextStream('localhost', 9999)\n",
    "\n",
    "# Process each batch of events\n",
    "dstream.foreachRDD(process_batch)\n",
    "\n",
    "# Start the Spark Streaming context\n",
    "ssc.start()\n",
    "ssc.awaitTermination()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63dc794f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b09878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f244ff93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b720d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c908f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
